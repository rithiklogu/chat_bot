{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e4b5ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def extracted_data(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_list = [Document(page_content=page.get_text()) for page in doc]\n",
    "    doc.close()\n",
    "    return text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks: 132\n"
     ]
    }
   ],
   "source": [
    "def text_split(data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(data)\n",
    "    return text_chunks\n",
    "\n",
    "pdf_path = r\"C:\\Users\\rithi\\Desktop\\GEN_AI\\chat_bot\\data\\Medicines_for_Cats_and_Dogs_final.pdf\"  \n",
    "\n",
    "data = extracted_data(pdf_path)\n",
    "text_chunks = text_split(data)\n",
    "\n",
    "print(\"Length of Text Chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def clean_and_tokenize_chunks(text_chunks):\n",
    "\n",
    "    cleaned_texts = []\n",
    "    all_tokens = []\n",
    "\n",
    "    for doc in text_chunks:\n",
    "        \n",
    "        text = doc.page_content.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s]', '', text)  \n",
    "        cleaned_texts.append(text)\n",
    "\n",
    "    \n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        all_tokens.append(tokens)\n",
    "\n",
    "    return cleaned_texts, all_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "899f2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts, all_tokens = clean_and_tokenize_chunks(text_chunks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rithi\\AppData\\Local\\Temp\\ipykernel_22664\\1915914874.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8eb5e30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a94a7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "GROQ_API_KEY=os.environ.get('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cfc81985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"chat-bot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"chat-bot-cbqrlrj.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"chat-bot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ec21ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3c150034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "36ef75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "da8ea993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1658054baf0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c17e6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ef533f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c66ee243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='99ab44a1-50d4-4d45-9b22-eb20a6a5b07d', metadata={}, page_content='affecting the ocular surface and include idoxuridine and trifluridine.'),\n",
       " Document(id='bfaee2bc-df51-4ee0-9fe1-058c72637dd4', metadata={}, page_content='a variety of indications, including but not limited to otitis externa, gingivitis, periodontal disease, \\nsuperficial skin infections, topical disinfection of wounds and perioperative skin antisepsis. \\n \\n7) \\nPovidone-iodine \\nThis iodophor antiseptic is widely used as an alternative of chlorhexidine gluconate for \\nperioperative skin antisepsis, post-operative application to surgical incisions, and emergency \\nantisepsis in patients with minor lacerations, abrasions and burns.'),\n",
       " Document(id='f78cf8ce-d3ad-4878-b055-83fb04fc8687', metadata={}, page_content='also useful for treatment of infections caused by bacteria that are resistant to first line agents. \\n \\n \\nTopical administration \\n \\nCore list \\n \\n1) \\nFusidic acid \\nThis fusidane is the first choice for management of otitis, eye and localized skin and wound \\ninfections associated with staphylococci. \\n \\n2) \\nFlorfenicol \\nAn increasingly used antibacterial agent for the management of staphylococcal otitis, usually as \\npart of a combination product that includes antifungal and corticosteroid drugs.')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5915c7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain_groq) (0.3.65)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain_groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rithi\\desktop\\gen_ai\\chat_bot\\env\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_groq) (2.4.0)\n",
      "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: langchain_groq\n",
      "Successfully installed langchain_groq-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6d27c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm =ChatGroq(model_name=\"llama3-8b-8192\",temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "242e9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2590906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6a272ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided context does not mention Acromegaly and gigantism.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0b8c9514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided context appears to be related to veterinary medicine and essential medicines, but it doesn't mention \"stats\".\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is stats?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdbbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64add57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f380580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d18194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8771a104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37c1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0a886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
